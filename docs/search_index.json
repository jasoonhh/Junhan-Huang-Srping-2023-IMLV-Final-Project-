[["index.html", "Credit Crad Default Prediction Chapter 1 Proposal 1.1 Motivation 1.2 Data 1.3 Models 1.4 Modeling Goal", " Credit Crad Default Prediction Junhan Huang 2023-05-01 Chapter 1 Proposal 1.1 Motivation The collapse of Silicon Valley Bank and Credit Suisse has had a significant impact on the financial industry and the economy as a whole. One of the major contributing factors to the collapse was the high number of defaults on credit cards issued by the banks. This highlights the importance of credit card client default prediction. 1.2 Data Data Resource: UCI: Default of credit card clients Data Set Data Variable Expalination: LIMIT_BAL : It includes both the individual consumer credit and his/her family (supplementary) credit. SEX: 1 = male; 2 = female EDUCATION: 1 = graduate school; 2 = university; 3 = high school; 4 = others MARRIAGE: 1 = married; 2 = single; 3 = others AGE: Year PAY_1 - PAY_6: Each of the repayment status variables takes on integer values between -1 and 9, where -1 represents payment made on time (duly), and values from 1 to 9 represent the number of months of delay in payment. BILL_AMT1 - BILL_AMT6: Amount of previous bill statement (NT dollar) The suffix i of variables means the past i-th month bill statement amount PAY_AMT1 - PAY_AMT6: Amount of previous payment (NT dollar); The suffix i of variables means the past i-th month previous payment amount 1.3 Models Logistic Regression Decision Tree Random Forest 1.4 Modeling Goal Predict whether or not a person will be a Credit Card defaulter based on the extracted features "],["exploratory-data-analysis.html", "Chapter 2 Exploratory Data Analysis 2.1 The Structure of Dataset 2.2 Data Visualization &amp; Analysis 2.3 EDA Conclusion", " Chapter 2 Exploratory Data Analysis 2.1 The Structure of Dataset We should find out the type and amount of unique values in each column of the dataset. Basing on the type of columns and the amount of unique value, we can identify which variables are numerical and categorical. ## Type Unique_Value_Amount ## ID character 30000 ## LIMIT_BAL numeric 81 ## SEX character 2 ## EDUCATION character 7 ## MARRIAGE character 4 ## AGE numeric 56 ## PAY_0 numeric 11 ## PAY_2 numeric 11 ## PAY_3 numeric 11 ## PAY_4 numeric 11 ## PAY_5 numeric 10 ## PAY_6 numeric 10 ## BILL_AMT1 numeric 22723 ## BILL_AMT2 numeric 22346 ## BILL_AMT3 numeric 22026 ## BILL_AMT4 numeric 21548 ## BILL_AMT5 numeric 21010 ## BILL_AMT6 numeric 20604 ## PAY_AMT1 numeric 7943 ## PAY_AMT2 numeric 7899 ## PAY_AMT3 numeric 7518 ## PAY_AMT4 numeric 6937 ## PAY_AMT5 numeric 6897 ## PAY_AMT6 numeric 6939 ## Default character 2 2.1.1 Data Identification From the data frame above, we can find “SEX”, “EDUCATION” and “MARRIAGE” have character value and “PAY_0”, “PAY_2”, “PAY_3”, “PAY_4”, “PAY_5”, “PAY_6” have numerical value but little unique value amount. Combined with the data description, we can recognize the above variables as categorical variables. To the rest variables except “ID” and “Default”, we will treat them as numerical variable. “ID” will be dropped because it have unique value for each row which it will not provide any information for prediction. “Default” is the label. 2.1.2 Feature Problem Detection There is a naming error because there is no variable named PAY_0 in the data description and missing the variable named PAY_1. The data description states that unique values of variables PAY_1 to PAY_6 should be -1, 1, 2, 3, 4, 5, 6, 7, 8, 9, which means the maxium of unique variable amount is 11. However, the unique value amount of PAY_1 to PAY_4 concluded above are all 11. Then we check the unique value of variable PAY_1 to PAY_6, we can find that there are two extra value “-2” and “0” which is not defined in data description. ## $PAY_1 ## [1] 2 -1 0 -2 1 3 4 8 7 5 6 ## ## $PAY_2 ## [1] 2 0 -1 -2 3 5 7 4 1 6 8 ## ## $PAY_3 ## [1] -1 0 2 -2 3 4 6 7 1 5 8 ## ## $PAY_4 ## [1] -1 0 -2 2 3 4 5 7 6 1 8 ## ## $PAY_5 ## [1] -2 0 -1 2 3 5 4 7 8 6 ## ## $PAY_6 ## [1] -2 2 0 -1 3 6 4 7 8 5 Similar with variable PAY_1 to PAY_6, variable EDUCATION should only have 4 but actually 7 in Structure data frame above. By checking the unique value of variable EDUCATION, we find there are 3 extra value 0, 5, 6. ## [1] &quot;2&quot; &quot;1&quot; &quot;3&quot; &quot;5&quot; &quot;4&quot; &quot;6&quot; &quot;0&quot; Similar with variable EDUCATION, variable EDUCATION should only have 3 but actually 4 in Structure data frame above. By checking the unique value of variable EDUCATION, we find there is extra value 0. ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;0&quot; 2.2 Data Visualization &amp; Analysis 2.2.1 Label: Default of credit card 77.88% of the observations in the data set belong to the non-default group (Default = 0). 22.12% of the observations in the data set belong to the default group (Default = 1). There are 23,364 observations in the non-default class and only 6,636 observations in the default class, which is a large difference in the number of observations, indicating a class imbalance. 2.2.2 Categorical Variable The data analysis of categorical variable is aiming to explore the relationship between the selected variable and the Default variable in a dataset. By grouping the data by these two variables and calculating the percentage of observations in each group, we can see how the percentage of defaults differs between males and females. Moreover, the chi-squared test is used to determine whether there is a significant association between Default and categorical feature. 2.2.2.1 SEX We firstly notice that the distribution of Default status is different between Male and Female, which indicates that there may be a difference in the proportion of males and females who default on their financial obligations. However, gender is a sensitive attribute and we should find more significant evidence to make a conclusion. ## ## Pearson&#39;s Chi-squared test with Yates&#39; continuity correction ## ## data: cont_table ## X-squared = 47.709, df = 1, p-value = 4.945e-12 \\(H_0:\\) There is no significant association between the categorical variable SEX and Default. \\(H_a:\\) There is significant association between the categorical variable SEX and Default. Given the Chi-Squared Test above, since the p-value is smaller than the common significance level of 0.05, we can reject the null hypothesis (\\(H_0\\)) at the 5% level of significance. This means that we do have sufficient evidence to conclude that there is a significant association between SEX and Default. 2.2.2.2 EDUCATION Because the value of EDUCATION defined in data description are only 1, 2, 3, and the proportion of undefined value is smaller enough (&lt;0.1%), we can ignore the information from the undefined value. The plot shows that the distribution of Default status is different between Education levels and revels a trend that the clients who have higher Education level will has lower possibility to default because there is lower proportion of default clients in the group of clients who has higher Education level. ## ## Pearson&#39;s Chi-squared test ## ## data: cont_table ## X-squared = 97, df = 2, p-value &lt; 2.2e-16 \\(H_0:\\) There is no significant association between the categorical variable EDUCATION and Default. \\(H_a:\\) There is significant association between the categorical variable EDUCATION and Default. Given the Chi-Squared Test above, since the p-value is smaller than the common significance level of 0.05, we can reject the null hypothesis (\\(H_0\\)) at the 5% level of significance. This means that we do have sufficient evidence to conclude that there is a significant association between EDUCATION and Default. 2.2.2.3 MARRIAGE Because the value of MARRIAGE defined in data description are only 1, 2, 3, and the proportion of undefined value is smaller enough (&lt;0.3%), we can ignore the information from the undefined value. The plot shows that the distribution of Default status is different between MARRIAGE levels ## ## Pearson&#39;s Chi-squared test ## ## data: cont_table ## X-squared = 30.446, df = 2, p-value = 2.448e-07 \\(H_0:\\) There is no significant association between the categorical variable MARRIAGE and Default. \\(H_a:\\) There is significant association between the categorical variable MARRIAGE and Default. Given the Chi-Squared Test above, since the p-value is smaller than the common significance level of 0.05, we can reject the null hypothesis (\\(H_0\\)) at the 5% level of significance. This means that we do have sufficient evidence to conclude that there is a significant association between MARRIAGE and Default. 2.2.2.4 Past Payment Action All 6 variable share similar bell-shaped right skewed distribution which is that value 0 has highest proportion, value -2 has secondly highest proportion and then value -1 has third.Only variable PAY_1 has a speacial case that value 1 share secondly highest proportion. 2.2.3 Numerical Variable The data analysis of numerical variable will focus on the distribution, statistics and inter-correlation between each numerical variable. 2.2.3.1 Amount of the given credit ## ## Welch Two Sample t-test ## ## data: LIMIT_BAL by Default ## t = 28.952, df = 11982, p-value &lt; 2.2e-16 ## alternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0 ## 95 percent confidence interval: ## 44740.91 51239.23 ## sample estimates: ## mean in group 0 mean in group 1 ## 178099.7 130109.7 The LIMIT_BAL distribution of default and non-default are similar, both of them are right-skewed and have extreme outlier. However, the mean of limited balance are differen t in two group, which indicates that non-default clients generally have higher limited balance than default clients. The statistics of them has great difference such as the mean and outlier of non-default is greater than default’s. From the result of T-Test whose null hypothesis is there is no difference between the Default’s credit limit mean and Non-Default’s credit limit mean, the p value is smaller than 2.2e-16 and consequently we have sigenificant evidence to reject the null hypothesis. 2.2.3.2 AGE ## ## Welch Two Sample t-test ## ## data: AGE by Default ## t = -2.3195, df = 10173, p-value = 0.02039 ## alternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0 ## 95 percent confidence interval: ## -0.56915863 -0.04778641 ## sample estimates: ## mean in group 0 mean in group 1 ## 35.41727 35.72574 The distribution of Age of default and non-default clients are slightly different which is that default clients has more average proportion in each age but non-default clients’ age are more centered, but both of distribution are right-skewed. However, the boxplot indicates that both of two kinds of clients have similar average age and have extreme outlier. – From the result of T-Test whose null hypothesis is there is no difference between the Default’s Age mean and Non-Default’s Age mean, the p value is 0.02039 and consequently we have sigenificant evidence to reject the null hypothesis under the significant level 0.05. 2.2.3.3 Amount of bill statement By comparing the six graphs, it can be seen that the amount of bills has fluctuated significantly in the past six months for both credit card defaulters and credit card defaulters. However, there is no significant difference in bill statement amount between credit card defaulters and credit card defaulters. The bill statement amount distribution of two kinds of clients are both right-skewed in all of the past 6 months. Because the bill statement amount of each month can show clients’ spending behavior which means the bill statement might be inter-correlated. From the corrplot, it can be said that all of 6 variable are highly inter-correlated because there correlation are all greater than 0.8 The correlation level decreases when time period gap is greater, which indicates than the next month bill statement amount is most correlated with current bill statement amount. 2.2.3.4 Amount of Payment By comparing the six graphs, we can observe that the amount of payment all gather in 0 with some extreme outlier in the past six months for both credit card defaulters and credit card defaulters. However, there is no significant difference in bill payment amount between credit card defaulters and credit card defaulters Because the bill payment amount of each month can show clients’ spending behavior which means the bill payment might be inter-correlated. From the corrplot, it can be said that all of 6 variable are less inter-correlated because there correlation are all smaller than 0.3 The correlation level decreases when time period gap is greater, which indicates than the next month bill payment amount is most correlated with current bill payment amount. 2.2.3.5 Correlation From the overall correlation plot, we can find variable AGE and LIMIT_BAL are not correlated with other numerical variable 2.3 EDA Conclusion 2.3.1 Feature Selection Following by the EDA of each variable, we decide to choose “SEX”, “EDUCATION”, “MARRIAGE”, “PAY_1”, “AGE”, “LIMIT_BAL”, “BILL_AMT1”, “PAY_AMT1” for further model building. 2.3.2 Data Wrangling and Spliting Data wrangling includes data cleaning, transforming, and encoding. Randomly Split the data set to get train and test data set. The Dimension of Train Data: 24000 x 9 The Dimension of Test Data: 6000 x 9 "],["logistic-regression.html", "Chapter 3 Logistic Regression 3.1 Introduction 3.2 Model Fitting 3.3 Model Interpretation 3.4 Model Evaluation", " Chapter 3 Logistic Regression 3.1 Introduction Logistic regression is one of the most easy but powerful statistical method used to analyze the relationship between a binary dependent variable and one or more independent variables. It estimates the probability of an event occurring $ p=$ and the coefficients are commonly estimated via maximum likelihood estimation. The Assumption of Logistic Regression The Response Variable is Binary The Observations are Independent There is No Multicollinearity Among Explanatory Variables There are No Extreme Outliers There is a Linear Relationship Between Explanatory Variables and the Logit of the Response Variable The Sample Size is Sufficiently Large 3.2 Model Fitting The Logistic regression model is built below ## ## Call: ## glm(formula = Default ~ ., family = &quot;binomial&quot;, data = train_data) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.9054 -0.6095 -0.5264 -0.3221 3.6263 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -13.67319 87.77502 -0.156 0.87621 ## SEX2 -0.16768 0.03546 -4.728 2.26e-06 *** ## EDUCATION1 10.94692 87.77272 0.125 0.90075 ## EDUCATION2 10.97574 87.77272 0.125 0.90049 ## EDUCATION3 10.85705 87.77273 0.124 0.90156 ## EDUCATION4 9.69429 87.77396 0.110 0.91206 ## EDUCATION5 9.37635 87.77325 0.107 0.91493 ## EDUCATION6 10.51929 87.77399 0.120 0.90461 ## MARRIAGE1 1.30127 0.63217 2.058 0.03955 * ## MARRIAGE2 1.14571 0.63223 1.812 0.06996 . ## MARRIAGE3 1.26239 0.65139 1.938 0.05263 . ## PAY_1-1 0.15835 0.07595 2.085 0.03706 * ## PAY_10 -0.39649 0.07615 -5.207 1.92e-07 *** ## PAY_11 0.86565 0.07756 11.161 &lt; 2e-16 *** ## PAY_12 2.22171 0.08530 26.045 &lt; 2e-16 *** ## PAY_13 2.56335 0.16513 15.523 &lt; 2e-16 *** ## PAY_14 2.26224 0.30262 7.475 7.69e-14 *** ## PAY_15 1.05617 0.43946 2.403 0.01625 * ## PAY_16 1.94302 0.71566 2.715 0.00663 ** ## PAY_17 2.10503 0.84207 2.500 0.01242 * ## PAY_18 1.48281 0.51279 2.892 0.00383 ** ## AGE 0.03930 0.02002 1.963 0.04965 * ## LIMIT_BAL -0.35759 0.02375 -15.054 &lt; 2e-16 *** ## BILL_AMT1 0.13415 0.02294 5.849 4.96e-09 *** ## PAY_AMT1 -0.24823 0.03996 -6.212 5.23e-10 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 25458 on 23999 degrees of freedom ## Residual deviance: 21329 on 23975 degrees of freedom ## AIC: 21379 ## ## Number of Fisher Scoring iterations: 11 3.3 Model Interpretation 3.3.1 Model Information Given the table above, we can gain information about the logistic regression we fit, such as : Estimated Coefficients for each predictor variable, which is the column named “Estimate” p value : The column named “Pr(&gt;|z|)”; The null hypothesis is the corresponding coefficient is zero, if the p-value is small enough (usually 0.05), we have significant evidence to reject the null hypothesis EDUCATION\"X\"(X indicate the level of education) might be the set of the most important variables because the magnitude of coefficients represent how much they impact the prediction and all of the EDUCATION\"X\" magnitude are large. However, the summary of the logistic regression model shows that none of the p-value of EDUCATION\"X\" exceeded general threshold of significance, indicating that the result is not statistically significant. Consequently, we need more evaluation criteria to indentify the importance of feature. 3.3.2 Shapley Values The Shapley value is the average contribution of a feature value to the prediction in different coalitions. The plot above shows the mean absolute SHAP values of the logistic regression we built, which represent the each variable’s impact to prediction. Because higher absolute mean Shapley value indicates a stronger impact to the prediction, the variable PAY_1 having highest Shapley value is the most important for prediction and the LIMIT_BAL is the second. 3.3.3 Partial Dependence Plots (PDP) 3.3.3.1 Partial Dependence Plots of variable PAY_1 The PDP of Limit Balance shows that the relationship between the probability of default and PAY_1 are non-monomaniacal while all other features remain constant. More specifically, the probability of default fluctuates with the late payment status severity (The increase in delinquent months has paralleled the increase in severity) and attains highest at PAY_1 = 3. Moreover, the distribution of contribution of each level of PAY_1 is coincide with the distribution of the coefficients of each level of PAY_1. 3.3.3.2 Partial Dependence Plots of variable LIMIT_BAL The PDP of Limit Balance shows that the relationship between the probability of default and Limit Balance are monomaniacal. More specifically, the probability of default will decrease if the limit balance increases. However, their relationship is non-linear because there is concave trend. Th trend also matches the exploratory data analysis of PAY_1 which states that the mean Limit Balance of the default clients are lower than non-default clients. 3.4 Model Evaluation Because the model purpose is accurately predicting the credit card default clients, we should not only focus on the accuracy but also the sensitivity, which is the proportion of actual positive cases. From the plot we can find that accuracy and sensitivity achieve the best balance between correctly identifying positive cases (sensitivity) , while still maintaining a high overall rate of correct classifications (accuracy) at threshold = 0.2147215. The best accuracy is 0.6521667 and the best sensitivity is 0.6527132. The plot above represents the Receiver Operating Characteristic (ROC) curves of the random forest model. Area Under the Curve (AUC), which measures the area under the Receiver Operating Characteristic (ROC) curve, is a metric used to evaluate the performance of a binary classification model. Given the AUC of model = 0.707 and the TPR at the optimal threshold, we can make a conclusion that the logistic regression model is good if we focus on accuracy and sensitivity. "],["decision-tree.html", "Chapter 4 Decision Tree 4.1 Introduction 4.2 Model Fitting 4.3 Model Interpreation 4.4 Model Evaluation", " Chapter 4 Decision Tree 4.1 Introduction Decision Tree is a non-parametric supervised model, which indicates that there is no particular assumptions about the kind of mapping function. we will use CART decision tree, which is a top-down greedy approach to find the partition minimizing the Gini Index, to predict whether or not a person will be a Credit Card defaulter. 4.2 Model Fitting 4.2.1 Complexity Parameter (cp) Complexity parameter is a regularization parameter that controls the tree size. Larger cp makes the tree simpler/smaller while smaller cp makes tree more complex. The line chart cp versus cross-validated error rate roughly shows that cross-validated error rate will decrease initially and increase later when cp is increasing. The tree model attains lowest cross-validated error rate when cp = 0.00101. 4.2.2 Decision Tree The left plot is the full decision tree model and the right is the pruned decision tree model. Given the two plot above, we can find that the pruning with cp = 0.00101 can significantly reduce the decision tree model complexity (From depth 28 to depth 3). As the full decision tree is too complex to read and interpret, we would pay more attention on the pruned tree model. In each node of the the pruned tree model, we can find the major label of the data in the node which is on the top of the node, the gini index which represent the measure of impurity and is at the middle of the node, and the percentage which represents the proportion of training instances that belong to each class at that node and is at the bottom of node. The conditioanl statement in the middle of branch is the criteria of splitting. 4.3 Model Interpreation 4.3.1 Shapley Values The Shapley value is the average contribution of a feature value to the prediction in different coalitions. The plot above shows the mean absolute SHAP values of the decision tree model we built, which represent the each variable’s impact to prediction. Both of the full tree model and pruned tree model have same feature importance distribution and the most importance feature is PAY_1 and the second is BILL_AMT1. However, by comparing the magnitude of mean absolute shap value between the full tree model and pruned tree model, we can find the pruned decision tree model treat the PAY_1 more important than full decision tree. 4.3.2 Partial Dependence Plots (PDP) 4.3.2.1 Partial Dependence Plots of variable PAY_1 From the Partial Dependence Plot of PAY_1 from the full tree model and the pruned tree model, we can see that the pruning model’s distribution of level contribution of PAY_1 is less volatile than that of the full model. This information suggests that clients who have a history of less delay in their payments (lower PAY_1 level) are less likely to default on their credit card payments. The cut off of the level impact toward prediction at PAY_1 = 2 matches both models partition criteria at PAY_1. However, there is a paradoxical phenomenon where the full decision tree model’s contribution distribution of PAY_1 levels is completely opposite to the logistic regression model’s contribution distribution of PAY_1 levels. This phenomenon could be explained by the exploratory data analysis of PAY_1, where the frequency distribution of PAY_1 levels among default clients is similar to the full decision tree model’s distribution of level contribution of PAY_1. 4.3.2.2 Partial Dependence Plots of variable BILL_AMT1 Similar to the PAY_1 variable, the distribution of level contribution of BILL_AMT1 in the pruned model is less volatile than that of the full model. In the partial dependence plot for BILL_AMT1 from the full model, we can observe that the contribution falls in a fluctuating manner as the bill statement amount from the previous month increases. 4.4 Model Evaluation ## Accuracy of Full Model: 0.6995 ## Accuracy of Pruned Model: 0.8235 The two plots above represent the Receiver Operating Characteristic (ROC) curves of the full model and the pruned model. The red line vertical to the X-axis represents the optimal threshold evaluated by the Youden index. The Area Under the Curve (AUC), which measures the area under the ROC curve, is a metric used to evaluate the performance of a binary classification model. Given the AUC of the full model is 0.7176, the AUC of the pruned model is 0.642, and the full model achieves the same level of TPR as the pruned model with a lower FPR, we can conclude that the full tree model is better if we focus on predicting true default clients (sensitivity). However, we can barely interpret the information given from the visualization of the full model, which can be seen as a trade-off between interpretability and model performance. "],["random-forest.html", "Chapter 5 Random Forest 5.1 Model Interpreation 5.2 Model Evaluation", " Chapter 5 Random Forest 5.1 Model Interpreation Because the random forest is a black box model, we interpret it direactly by Shapley value and PDP. 5.1.1 Shapley Values The Shapley value is the average contribution of a feature value to the prediction in different coalitions. The plot above shows the mean absolute SHAP values of the random forest model we built, which represent the each variable’s impact to prediction. The feature importance distribution is concurrent with logistic regression model’s but different with decision tree’s, which states that the most importance feature is PAY_1 and the second is LIMIT_BAL. 5.1.2 Partial Dependence Plots (PDP) 5.1.2.1 Partial Dependence Plots of variable PAY_1 The random forest model’s distribution of level contribution of PAY_1 are similar with the full decision tree model’s distribution of level contribution of PAY_1, which states that lower level of PAY_1 (Indicating less delaying) have stronger impact to the prediction while other variable remain as constant. This information suggests that clients who have a history of less delaying in their payments (lower PAY_1 level) are less likely to default on their credit card payments. Because of the similarity, the paradoxical phenomenon that the full random forest model’s distribution of level contribution of PAY_1 is completely opposite with the logistic regression model’s distribution of level contribution of PAY_1 also exists. 5.1.2.2 Partial Dependence Plots of variable LIMIT_BAL The PDP of Limit Balance shows that the relationship between the probability of default and Limit Balance is non-monotonic More specifically, the probability of default will initially increase, and then decrease, and finally remain stable when the limit balance increases. The assumption of this relationship between the probability of default and Limit Balance is all other variables remain constant. 5.2 Model Evaluation ## Accuracy: 0.7293333 The plot above represents the Receiver Operating Characteristic (ROC) curves of the random forest model. The red line vertical to the X-axis represents the optimal threshold evaluated by the Youden index. Area Under the Curve (AUC), which measures the area under the Receiver Operating Characteristic (ROC) curve, is a metric used to evaluate the performance of a binary classification model. Given the AUC of model = 0.743 and the TPR at the optimal threshold, we can make a conclusion that the random forest model is good if we focus on accuracy and sensitivity. However, the random forest is a black box model, which means we cannot interpret it locally, but have to explain it using other models, such as Shapley values or partial dependence plots of variables. The lack of local interpretablilty is a representation of trade-off between interpretability and model performance. "],["reflections.html", "Chapter 6 Reflections 6.1 Model Comparison 6.2 Main Takeaway 6.3 Limitaion 6.4 Future Work", " Chapter 6 Reflections 6.1 Model Comparison The information of three model we built in this project is summerized below Model Accuracy Sensitivity Interpretablilty Logistic Regression 0.6521667 0.6527132 High: Can interpret by its model summary Decision Tree 0.6995 0.6 Low: Can partially interpret by its model visualization Random Forest 0.7293333 0.6077519 Low: Black Box Model There is an explicit trade-off between accuracy and sensitivity which means we would have lower overall accuracy if we are focusing on correctly detecting default clients. Given the table above, random forest achieve the balance between accuracy and sensitivity and consequently it might the most appropreate model in this project. 6.2 Main Takeaway The main takeaway of this project is building useful model random forest to identify potential default clients with acceptable accuracy and sensitivity. Moreover, we realize that the previous month payment behavior, limited balance, and last month bill statement amount are the top 3 most important variable to identify default clients. Last but not least, we gain meaningful experience about interpreting the model we learned before via new methods such us Shaply Values and partial dependence plot. 6.3 Limitaion Data : Noisy: There are unexplainable values in categorical variables and extreme outlier in numerical variables, which might affect the performance and robustness of model. Imbalance : The data set is severely imbalanced. Model: Random Forest Lack of Interpretablilty: Random Forest is too complex to understand the relationship between the variable and prediction. Weak to imbalanced data sets: Random Forest will be biased towards the majority class. Computational Complexity High 6.4 Future Work We can implement resampling method such as Synthetic Minority Over-sampling Technique (SMOTE) on original data set to eliminate the effect of imbalance and improve the model performance which might provide better prediction on credit card default clients. Moreover, we can also implement cost-sensitive learning algorithms such as CostSensitiveRandomForest. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
